\documentclass[english,11pt,twoside,a4paper]{article}
\usepackage[left=2cm,top=1cm,right=2cm,nohead,nofoot]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{graphicx}
\begin{document}
\author{
  Niemist√∂, Jesse
  \and
  Muona, Leo
  \and
  Hilden, Matias
}
\title{Evaluation}

\maketitle

\section{Dropped features}

Due to both algorithmic and mechanical difficulties, we had to drop the vertical rotation motor.

\section{Testing}

We performed two kind of tests on the project: Use case tests for determing wether the prototype works as intended, and perfomance testing to measure cycle speed during rest (no motion) and calculation (motion).

\subsection{Use case testing}

Use case testing is done in a room where at the start of the test the system has been initialized and program ran. Motor rotation at the initialization should be at the center of robot. Use case tests are identified with UC-prefix and index number suffix.

\textbf{UC-1: No motion test}

The first use case test is a test where no movement is at camera's field of view. The correct result is camera taking pictures (indicated via red blinking light) and no movement by the motor or sound from the audio system is played. The test result was successful. 

\textbf{UC-2: Left-side motion test}

The second use case test is a test where there is a single movement at left side of camera's field of view. Correct result contains the following characteristics:

\begin{itemize}
  \item Camera: Takes two pictures from which the movement is recognized. Then halts the picture taking for the time of motor rotation.
  \item Sound: A random sound clip is played to greet the person who has done the movement.
  \item Motor: Motor axis rotates the camera to left so that the center of camera points at movement spot.
\end{itemize}

The test result was "okay". That is, the correct motor rotation was made and soundclip was played. However targetting is not very accurate.

\textbf{UC-3: Right-side motion test}

The third use case test is a test where there is a single movement at right side of camera's field of view. Correct result contains the following characteristics:

\begin{itemize}
  \item Camera: Takes two pictures from which the movement is recognized. Then halts the picture taking for the time of motor rotation.
  \item Sound: A random sound clip is played to greet the person who has done the movement.
  \item Motor: Motor axis rotates the camera to right so that center of camera points at movement spot.
\end{itemize}

The test result was "okay". Rotation was made towards the correct spot and soundclip was played. However, like in previous test, targetting is not very accurate.

\textbf{UC-4: Maximum rotation test}

The fourth use case test is a test to check maximum rotation edges. This test includes movement done first on the left side of the camera, just in camera's field of view, multiple times untill camera no longer rotates to left. Then, same is done at the right side of the camera's field of view untill camera has turned multiple times untill camera no longer rotates to right. Test case correct result includes the following:

\begin{itemize}
  \item Camera: Takes pictures every time movement is recognized.
  \item Sound: Plays audio clip every time movement is recognized.
  \item Motor: Camera turns left multiple times when movement is recognized, then stops at 30 degrees from the center, which is the safe limit. When movement is done at the right side of camera, camera turns right multiple times when movement is recognized, then stops at 30 degrees from the center, which is the safe limit.
\end{itemize}

Test result was successful. As a sidenote, when running the test case again, the camera moves different lengths at a time.

\subsection{Performance testing}

Perfomance tests will programmically time the length picture cycles. Each cycle contains the following: taking a new picture, calculating differences between old and new pictures and calculating the rotation angle in case motion was detected. Rotation and audio playback are left out of the cycle as they depend on rotation and audio file length, thus impacting the results in a non-informative way.

The time used by the program "raspistill" was externally measured to be around 1200 milliseconds. This result is used when analyzing cycle performance below.

\textbf{No motion}

The turret was set to watch a direction with no motion and the program was started. The results in table \ref{cycle_times_no_motion}

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{| l | l |}
      \hline
      Cycle number & Length in milliseconds \\ \hline
      01 & 3101 \\ \hline
      02 & 1927 \\ \hline
      03 & 1929 \\ \hline
      04 & 1930 \\ \hline
      05 & 1927 \\ \hline
      06 & 1928 \\ \hline
      07 & 1933 \\ \hline
      08 & 1959 \\ \hline
      09 & 1928 \\ \hline
      10 & 1943 \\ \hline
    \end{tabular}
    \caption{Cycle times with no motion}
  \end{center}
  \label{cycle_times_no_motion}
\end{table}

The first cycle takes approximately twice as long as other cycles because the program takes two pictures in a row. Excluding that first cycle, the cycle time average is 1927 milliseconds. As the raspistill call takes about 1200 milliseconds, our difference calculation algorithm seems to take about 700 milliseconds. Cycle time is more than we would like, but still within acceptable limits.

\textbf{Motion}

The turret was set to watch one of our project members who created motion. The results are in table \ref{cycle_times_motion}

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{| l | l |}
      \hline
      Cycle number & Length in milliseconds \\ \hline
      01 & 3101 \\ \hline
      02 & 3196 \\ \hline
      03 & 3131 \\ \hline
      04 & 3192 \\ \hline
      05 & 3147 \\ \hline
      06 & 3169 \\ \hline
      07 & 3201 \\ \hline
      08 & 3161 \\ \hline
      09 & 3207 \\ \hline
      10 & 3193 \\ \hline
    \end{tabular}
    \caption{Cycle times with motion}
  \end{center}
  \label{cycle_times_motion}
\end{table}

This time all cycles need to take two pictures in a row. This is because we have to reset the taken pictures after detecting motion (this is because the pictures no longer represent a still state and the camera has also rotated). Cycle time with motion averages to 3483 milliseconds, of which 2400 milliseconds are taken by raspistill calls. This leaves about 700 milliseconds for difference calculation and 300 milliseconds for rotation calculation. Here the cycle time is definately more than we would like.

\section{Improvements}

Improvements to the project can be made on software side of things. The following issues can be improved:

\begin{itemize}
  \item Slow camera usage: This issue can be resolved by implementing the used raspistill program in our own code. This can be done relatively easily as raspistill is an open source program and does not conflict with our software licensing (GPLv3). It merely requires time.
  \item Inaccurate motion detection algorithm: This issue is a bit harder to solve, but it can propably be done by precomputing static scenery and/or a set of three pictures for difference calculation. This way we should be able to know where the moving object is instead of the algorithm showing two moving objects (starting and end location of the moving object).
  \item Unstable audio calls: Resolving this issue requires a firmware fix to the Raspberry Pi. Should such fix be made available, we can easily update it to our project.
  \item Remote control: This is more a new feature than an existing issue. Remote control via network connection is easy to implement and allows some interesting use cases.
\end{itemize}

\end{document}
